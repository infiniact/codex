use crate::error::ApiError;
use crate::provider::Provider;
use crate::requests::headers::build_conversation_headers;
use crate::requests::headers::insert_header;
use crate::requests::headers::subagent_header;
use crate::turn_signing::TurnSignature;
use codex_protocol::models::ContentItem;
use codex_protocol::models::FunctionCallOutputContentItem;
use codex_protocol::models::ReasoningItemContent;
use codex_protocol::models::ResponseItem;
use codex_protocol::protocol::SessionSource;
use http::HeaderMap;
use serde_json::Value;
use serde_json::json;
use std::collections::HashMap;

/// Assembled request body plus headers for Chat Completions streaming calls.
pub struct ChatRequest {
    pub body: Value,
    pub headers: HeaderMap,
}

pub struct ChatRequestBuilder<'a> {
    model: &'a str,
    instructions: &'a str,
    input: &'a [ResponseItem],
    tools: &'a [Value],
    conversation_id: Option<String>,
    session_source: Option<SessionSource>,
    /// æ˜¯å¦ä¸ºç”¨æˆ·ä¸»åŠ¨å‘é€ï¼ˆç”¨äºæœåŠ¡ç«¯ç»Ÿè®¡ï¼‰
    is_user_turn: bool,
}

impl<'a> ChatRequestBuilder<'a> {
    pub fn new(
        model: &'a str,
        instructions: &'a str,
        input: &'a [ResponseItem],
        tools: &'a [Value],
    ) -> Self {
        Self {
            model,
            instructions,
            input,
            tools,
            conversation_id: None,
            session_source: None,
            is_user_turn: true, // é»˜è®¤ä¸ºç”¨æˆ·ä¸»åŠ¨å‘é€
        }
    }

    pub fn conversation_id(mut self, id: Option<String>) -> Self {
        self.conversation_id = id;
        self
    }

    pub fn session_source(mut self, source: Option<SessionSource>) -> Self {
        self.session_source = source;
        self
    }

    /// è®¾ç½®æ˜¯å¦ä¸ºç”¨æˆ·ä¸»åŠ¨å‘é€
    pub fn is_user_turn(mut self, value: bool) -> Self {
        self.is_user_turn = value;
        self
    }

    pub fn build(self, _provider: &Provider) -> Result<ChatRequest, ApiError> {
        let mut messages = Vec::<Value>::new();
        messages.push(json!({"role": "system", "content": self.instructions}));

        let input = self.input;

        // é¢„æ‰«æï¼šæ”¶é›†æ‰€æœ‰æœ‰å¯¹åº” FunctionCallOutput çš„ call_id
        // è¿™æ ·æˆ‘ä»¬å¯ä»¥ç¡®ä¿æ¯ä¸ª tool_calls éƒ½æœ‰å¯¹åº”çš„ tool å“åº”
        let call_ids_with_output: std::collections::HashSet<String> = input
            .iter()
            .filter_map(|item| {
                if let ResponseItem::FunctionCallOutput { call_id, .. } = item {
                    Some(call_id.clone())
                } else if let ResponseItem::CustomToolCallOutput { call_id, .. } = item {
                    Some(call_id.clone())
                } else {
                    None
                }
            })
            .collect();

        let mut reasoning_by_anchor_index: HashMap<usize, String> = HashMap::new();
        let mut last_emitted_role: Option<&str> = None;
        for item in input {
            match item {
                ResponseItem::Message { role, .. } => last_emitted_role = Some(role.as_str()),
                ResponseItem::FunctionCall { .. } | ResponseItem::LocalShellCall { .. } => {
                    last_emitted_role = Some("assistant")
                }
                ResponseItem::FunctionCallOutput { .. } => last_emitted_role = Some("tool"),
                ResponseItem::Reasoning { .. } | ResponseItem::Other => {}
                ResponseItem::CustomToolCall { .. } => {}
                ResponseItem::CustomToolCallOutput { .. } => {}
                ResponseItem::WebSearchCall { .. } => {}
                ResponseItem::GhostSnapshot { .. } => {}
                ResponseItem::CompactionSummary { .. } => {}
            }
        }

        let mut last_user_index: Option<usize> = None;
        for (idx, item) in input.iter().enumerate() {
            if let ResponseItem::Message { role, .. } = item
                && role == "user"
            {
                last_user_index = Some(idx);
            }
        }

        if !matches!(last_emitted_role, Some("user")) {
            for (idx, item) in input.iter().enumerate() {
                if let Some(u_idx) = last_user_index
                    && idx <= u_idx
                {
                    continue;
                }

                if let ResponseItem::Reasoning {
                    content: Some(items),
                    ..
                } = item
                {
                    let mut text = String::new();
                    for entry in items {
                        match entry {
                            ReasoningItemContent::ReasoningText { text: segment }
                            | ReasoningItemContent::Text { text: segment } => {
                                text.push_str(segment)
                            }
                        }
                    }
                    if text.trim().is_empty() {
                        continue;
                    }

                    let mut attached = false;
                    if idx > 0
                        && let ResponseItem::Message { role, .. } = &input[idx - 1]
                        && role == "assistant"
                    {
                        reasoning_by_anchor_index
                            .entry(idx - 1)
                            .and_modify(|v| v.push_str(&text))
                            .or_insert(text.clone());
                        attached = true;
                    }

                    if !attached && idx + 1 < input.len() {
                        match &input[idx + 1] {
                            ResponseItem::FunctionCall { .. }
                            | ResponseItem::LocalShellCall { .. } => {
                                reasoning_by_anchor_index
                                    .entry(idx + 1)
                                    .and_modify(|v| v.push_str(&text))
                                    .or_insert(text.clone());
                            }
                            ResponseItem::Message { role, .. } if role == "assistant" => {
                                reasoning_by_anchor_index
                                    .entry(idx + 1)
                                    .and_modify(|v| v.push_str(&text))
                                    .or_insert(text.clone());
                            }
                            _ => {}
                        }
                    }
                }
            }
        }

        let mut last_assistant_text: Option<String> = None;

        for (idx, item) in input.iter().enumerate() {
            match item {
                ResponseItem::Message { role, content, .. } => {
                    let mut text = String::new();
                    let mut items: Vec<Value> = Vec::new();
                    let mut saw_image = false;

                    for c in content {
                        match c {
                            ContentItem::InputText { text: t }
                            | ContentItem::OutputText { text: t } => {
                                text.push_str(t);
                                items.push(json!({"type":"text","text": t}));
                            }
                            ContentItem::InputImage { image_url } => {
                                saw_image = true;
                                items.push(
                                    json!({"type":"image_url","image_url": {"url": image_url}}),
                                );
                            }
                        }
                    }

                    if role == "assistant" {
                        if let Some(prev) = &last_assistant_text
                            && prev == &text
                        {
                            continue;
                        }
                        last_assistant_text = Some(text.clone());
                    }

                    let content_value = if role == "assistant" {
                        json!(text)
                    } else if saw_image {
                        json!(items)
                    } else {
                        json!(text)
                    };

                    let mut msg = json!({"role": role, "content": content_value});
                    if role == "assistant"
                        && let Some(reasoning) = reasoning_by_anchor_index.get(&idx)
                        && let Some(obj) = msg.as_object_mut()
                    {
                        obj.insert("reasoning".to_string(), json!(reasoning));
                    }
                    messages.push(msg);
                }
                ResponseItem::FunctionCall {
                    name,
                    arguments,
                    call_id,
                    thought_signature,
                    ..
                } => {
                    // å°è¯•å°† arguments å­—ç¬¦ä¸²è§£æä¸º JSON å¯¹è±¡
                    // æŸäº› APIï¼ˆå¦‚ Anthropicã€Geminiï¼‰æœŸæœ› arguments æ˜¯å¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²
                    // OpenAI å…¼å®¹ API é€šå¸¸æ¥å—å­—ç¬¦ä¸²æ ¼å¼
                    let arguments_value: Value = serde_json::from_str(arguments)
                        .unwrap_or_else(|_| json!(arguments));

                    // æ£€æŸ¥è¿™ä¸ª FunctionCall æ˜¯å¦æœ‰å¯¹åº”çš„ FunctionCallOutput
                    // å¦‚æœæ²¡æœ‰ï¼Œåˆ™è½¬æ¢ä¸ºæ–‡æœ¬æ¶ˆæ¯ï¼Œé¿å… OpenRouter æŠ¥é”™
                    // "insufficient tool messages following tool_calls message"
                    if !call_ids_with_output.contains(call_id) {
                        let description = format!(
                            "[Tool Call: {}]\nArguments: {}\nCall ID: {}\n(No output recorded)",
                            name,
                            serde_json::to_string_pretty(&arguments_value).unwrap_or_else(|_| arguments.clone()),
                            call_id
                        );
                        let mut msg = json!({
                            "role": "assistant",
                            "content": description
                        });
                        if let Some(reasoning) = reasoning_by_anchor_index.get(&idx)
                            && let Some(obj) = msg.as_object_mut()
                        {
                            obj.insert("reasoning".to_string(), json!(reasoning));
                        }
                        messages.push(msg);
                        continue;
                    }

                    let function_obj = json!({
                        "name": name,
                        "arguments": arguments_value,
                    });

                    // ğŸ”§ ä¿®å¤ï¼šthought_signature åº”è¯¥æ”¾åœ¨ tool_call çº§åˆ«ï¼Œè€Œä¸æ˜¯ function çº§åˆ«
                    // å‚è€ƒï¼šhttps://openrouter.ai/docs/guides/best-practices/reasoning-tokens
                    let mut tool_call_obj = json!({
                        "id": call_id,
                        "type": "function",
                        "function": function_obj,
                    });

                    // Add thought_signature at tool_call level (NOT inside function object)
                    if let Some(sig) = &thought_signature {
                        if let Some(obj) = tool_call_obj.as_object_mut() {
                            obj.insert("thought_signature".to_string(), json!(sig));
                        }
                        tracing::warn!(
                            "ğŸ§  [ChatRequestBuilder::build] æ·»åŠ  thought_signature åˆ° tool_call: call_id={}, sig_len={}",
                            call_id,
                            sig.len()
                        );
                    }

                    let mut msg = json!({
                        "role": "assistant",
                        "content": null,
                        "tool_calls": [tool_call_obj]
                    });

                    // ğŸ†• ä¸º OpenRouter/Gemini æ·»åŠ  reasoning_detailsï¼ˆåœ¨ message çº§åˆ«ï¼‰
                    // æ ¼å¼: "reasoning_details":[{"id":"tool_xxx", "type":"reasoning.encrypted", "data":"...", "format":"google-gemini-v1"}]
                    if let Some(sig) = &thought_signature
                        && let Some(obj) = msg.as_object_mut()
                    {
                        obj.insert("reasoning_details".to_string(), json!([{
                            "id": call_id,
                            "type": "reasoning.encrypted",
                            "data": sig,
                            "format": "google-gemini-v1"
                        }]));
                        tracing::debug!(
                            "ğŸ§  [ChatRequestBuilder::build] æ·»åŠ  reasoning_details: call_id={}, sig_len={}",
                            call_id,
                            sig.len()
                        );
                    }

                    if let Some(reasoning) = reasoning_by_anchor_index.get(&idx)
                        && let Some(obj) = msg.as_object_mut()
                    {
                        obj.insert("reasoning".to_string(), json!(reasoning));
                    }
                    messages.push(msg);
                }
                ResponseItem::LocalShellCall {
                    id,
                    call_id: _,
                    status,
                    action,
                } => {
                    // LocalShellCall æ²¡æœ‰å¯¹åº”çš„ tool å“åº”æ¶ˆæ¯ï¼Œæ‰€ä»¥ä¸èƒ½ä½œä¸º tool_calls å‘é€
                    // å¦åˆ™ä¼šå¯¼è‡´ OpenRouter æŠ¥é”™: "insufficient tool messages following tool_calls message"
                    // å°†å…¶è½¬æ¢ä¸ºæ™®é€šçš„ assistant æ–‡æœ¬æ¶ˆæ¯
                    let action_str = serde_json::to_string_pretty(action).unwrap_or_default();
                    let content = format!(
                        "[Local Shell Call]\nID: {}\nStatus: {:?}\nAction: {}",
                        id.clone().unwrap_or_default(),
                        status,
                        action_str
                    );
                    let mut msg = json!({
                        "role": "assistant",
                        "content": content
                    });
                    if let Some(reasoning) = reasoning_by_anchor_index.get(&idx)
                        && let Some(obj) = msg.as_object_mut()
                    {
                        obj.insert("reasoning".to_string(), json!(reasoning));
                    }
                    messages.push(msg);
                }
                ResponseItem::FunctionCallOutput { call_id, output } => {
                    let content_value = if let Some(items) = &output.content_items {
                        let mapped: Vec<Value> = items
                            .iter()
                            .map(|it| match it {
                                FunctionCallOutputContentItem::InputText { text } => {
                                    json!({"type":"text","text": text})
                                }
                                FunctionCallOutputContentItem::InputImage { image_url } => {
                                    json!({"type":"image_url","image_url": {"url": image_url}})
                                }
                            })
                            .collect();
                        json!(mapped)
                    } else {
                        json!(output.content)
                    };

                    messages.push(json!({
                        "role": "tool",
                        "tool_call_id": call_id,
                        "content": content_value,
                    }));
                }
                ResponseItem::CustomToolCall {
                    id,
                    call_id: _,
                    name,
                    input,
                    status: _,
                } => {
                    // æ£€æŸ¥è¿™ä¸ª CustomToolCall æ˜¯å¦æœ‰å¯¹åº”çš„ CustomToolCallOutput
                    // æ³¨æ„ï¼šCustomToolCallOutput ä½¿ç”¨ call_idï¼Œè€Œ CustomToolCall çš„ id å­—æ®µæ˜¯å¯¹åº”çš„
                    let call_id_str = id.clone().unwrap_or_default();
                    if !call_ids_with_output.contains(&call_id_str) {
                        // æ²¡æœ‰å¯¹åº”çš„è¾“å‡ºï¼Œè½¬æ¢ä¸ºæ–‡æœ¬æ¶ˆæ¯
                        let input_str = serde_json::to_string_pretty(input).unwrap_or_default();
                        let description = format!(
                            "[Custom Tool Call: {name}]\nInput: {input_str}\nCall ID: {call_id_str}\n(No output recorded)"
                        );
                        messages.push(json!({
                            "role": "assistant",
                            "content": description
                        }));
                        continue;
                    }

                    // CustomToolCall ä½¿ç”¨æ ‡å‡†çš„ function ç±»å‹ï¼Œè€Œä¸æ˜¯ custom ç±»å‹
                    // å› ä¸º OpenRouter/OpenAI åªè¯†åˆ« function ç±»å‹çš„ tool_calls
                    let input_str = serde_json::to_string(input).unwrap_or_default();
                    messages.push(json!({
                        "role": "assistant",
                        "content": null,
                        "tool_calls": [{
                            "id": id,
                            "type": "function",
                            "function": {
                                "name": name,
                                "arguments": input_str,
                            }
                        }]
                    }));
                }
                ResponseItem::CustomToolCallOutput { call_id, output } => {
                    messages.push(json!({
                        "role": "tool",
                        "tool_call_id": call_id,
                        "content": output,
                    }));
                }
                ResponseItem::GhostSnapshot { .. } => {
                    continue;
                }
                ResponseItem::Reasoning { .. }
                | ResponseItem::WebSearchCall { .. }
                | ResponseItem::Other
                | ResponseItem::CompactionSummary { .. } => {
                    continue;
                }
            }
        }

        // æ£€æŸ¥æ˜¯å¦æœ‰ user æ¶ˆæ¯
        // æ™ºè°± GLM API è¦æ±‚ messages ä¸­å¿…é¡»åŒ…å«è‡³å°‘ä¸€æ¡ user è§’è‰²çš„æ¶ˆæ¯
        let has_user_message = messages.iter().any(|m| {
            m.get("role").and_then(|r| r.as_str()) == Some("user")
        });

        if !has_user_message {
            tracing::warn!(
                "âš ï¸ [ChatRequestBuilder::build] messages ä¸­æ²¡æœ‰ user æ¶ˆæ¯ï¼ŒGLM API å¯èƒ½ä¼šæŠ¥é”™ 1213"
            );
            // æ·»åŠ ä¸€æ¡ç©ºçš„ user æ¶ˆæ¯ï¼Œé˜²æ­¢ GLM API æŠ¥é”™
            // æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼ŒçœŸæ­£çš„é—®é¢˜åº”è¯¥åœ¨ä¸Šå±‚è§£å†³
            messages.push(json!({"role": "user", "content": "è¯·ç»§ç»­"}));
            tracing::warn!(
                "âš ï¸ [ChatRequestBuilder::build] å·²æ·»åŠ é»˜è®¤ user æ¶ˆæ¯"
            );
        }

        // æ„å»ºåŸºç¡€ payload
        let mut payload = json!({
            "model": self.model,
            "messages": messages,
            "stream": true,
        });

        // åªæœ‰å½“ tools éç©ºæ—¶æ‰æ·»åŠ  tools å‚æ•°
        // æ™ºè°± GLM API ç­‰ä¸å…¼å®¹ç©º tools æ•°ç»„ï¼Œä¼šå¯¼è‡´ 1213 é”™è¯¯
        if !self.tools.is_empty() {
            payload["tools"] = json!(self.tools);
        }

        // ğŸ†• ä¸º Gemini æ¨¡å‹å¯ç”¨æ¨ç†åŠŸèƒ½ï¼ˆOpenRouter éœ€è¦ï¼‰
        // æ£€æµ‹æ˜¯å¦ä¸º Gemini 3 æ¨¡å‹ï¼ˆéœ€è¦ thought_signature æ”¯æŒï¼‰
        let is_gemini_3 = self.model.contains("gemini-3")
            || self.model.contains("gemini/gemini-3")
            || self.model.contains("google/gemini-3");
        if is_gemini_3 {
            // OpenRouter éœ€è¦ reasoning å‚æ•°æ¥å¯ç”¨ Gemini çš„æ¨ç†åŠŸèƒ½
            // å‚è€ƒ: https://openrouter.ai/docs/guides/best-practices/reasoning-tokens
            payload["reasoning"] = json!({
                "enabled": true
            });
            // åŒæ—¶æ·»åŠ  stream_options ä»¥åŒ…å«æ¨ç†ç»†èŠ‚
            payload["stream_options"] = json!({
                "include_usage": true,
                "include_reasoning": true
            });
            tracing::warn!(
                "ğŸ§  [ChatRequestBuilder::build] Gemini 3 æ¨¡å‹æ£€æµ‹åˆ°ï¼Œå·²å¯ç”¨ reasoning åŠŸèƒ½"
            );
        }

        // ğŸ” DEBUG: æ‰“å°æ„å»ºçš„è¯·æ±‚ä½“
        tracing::debug!(
            "ğŸ“¤ [ChatRequestBuilder::build] model={}, messages_count={}, tools_count={}, has_tools_in_payload={}",
            self.model,
            messages.len(),
            self.tools.len(),
            payload.get("tools").is_some()
        );

        let mut headers = build_conversation_headers(self.conversation_id.clone());
        if let Some(subagent) = subagent_header(&self.session_source) {
            insert_header(&mut headers, "x-openai-subagent", &subagent);
        }

        // ğŸ”¢ æ·»åŠ  is_user_turn ç­¾å header
        if let Some(ref conv_id) = self.conversation_id {
            let signature = TurnSignature::sign(conv_id, self.is_user_turn);
            insert_header(&mut headers, "x-iaterm-turn", signature.turn_value());
            insert_header(&mut headers, "x-iaterm-turn-timestamp", &signature.timestamp.to_string());
            insert_header(&mut headers, "x-iaterm-turn-signature", &signature.signature);
            tracing::debug!(
                "ğŸ”¢ [ChatRequestBuilder::build] is_user_turn={}, turn={}, conv_id={}",
                self.is_user_turn,
                signature.turn_value(),
                conv_id
            );
        }

        Ok(ChatRequest {
            body: payload,
            headers,
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::provider::RetryConfig;
    use crate::provider::WireApi;
    use codex_protocol::protocol::SessionSource;
    use codex_protocol::protocol::SubAgentSource;
    use http::HeaderValue;
    use pretty_assertions::assert_eq;
    use std::time::Duration;

    fn provider() -> Provider {
        Provider {
            name: "openai".to_string(),
            base_url: "https://api.openai.com/v1".to_string(),
            query_params: None,
            wire: WireApi::Chat,
            headers: HeaderMap::new(),
            retry: RetryConfig {
                max_attempts: 1,
                base_delay: Duration::from_millis(10),
                retry_429: false,
                retry_5xx: true,
                retry_transport: true,
            },
            stream_idle_timeout: Duration::from_secs(1),
        }
    }

    #[test]
    fn attaches_conversation_and_subagent_headers() {
        let prompt_input = vec![ResponseItem::Message {
            id: None,
            role: "user".to_string(),
            content: vec![ContentItem::InputText {
                text: "hi".to_string(),
            }],
        }];
        let req = ChatRequestBuilder::new("gpt-test", "inst", &prompt_input, &[])
            .conversation_id(Some("conv-1".into()))
            .session_source(Some(SessionSource::SubAgent(SubAgentSource::Review)))
            .build(&provider())
            .expect("request");

        assert_eq!(
            req.headers.get("conversation_id"),
            Some(&HeaderValue::from_static("conv-1"))
        );
        assert_eq!(
            req.headers.get("session_id"),
            Some(&HeaderValue::from_static("conv-1"))
        );
        assert_eq!(
            req.headers.get("x-openai-subagent"),
            Some(&HeaderValue::from_static("review"))
        );
    }
}
